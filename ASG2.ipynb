{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Machine Learning\n",
    "## Multiple Linear Regression without using Scikit - Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104</td>\n",
       "      <td>3</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  bedroom   price\n",
       "0  2104        3  399900\n",
       "1  1600        3  329900\n",
       "2  2400        3  369000\n",
       "3  1416        2  232000\n",
       "4  3000        4  539900"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('home.txt', header = None, names =  ['size', 'bedroom', 'price'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment No 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2000.680851</td>\n",
       "      <td>3.170213</td>\n",
       "      <td>340412.659574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>794.702354</td>\n",
       "      <td>0.760982</td>\n",
       "      <td>125039.899586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>169900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1432.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>249900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1888.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>299900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2269.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>384450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4478.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>699900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              size    bedroom          price\n",
       "count    47.000000  47.000000      47.000000\n",
       "mean   2000.680851   3.170213  340412.659574\n",
       "std     794.702354   0.760982  125039.899586\n",
       "min     852.000000   1.000000  169900.000000\n",
       "25%    1432.000000   3.000000  249900.000000\n",
       "50%    1888.000000   3.000000  299900.000000\n",
       "75%    2269.000000   4.000000  384450.000000\n",
       "max    4478.000000   5.000000  699900.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   size     47 non-null     int64\n",
      " 1   bedroom  47 non-null     int64\n",
      " 2   price    47 non-null     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 1.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Independent and Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1, random_state=0)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:,  -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = int(len(data) * 0.8)\n",
    "X_train = X[:divider]\n",
    "X_test = X[divider:]\n",
    "y_train = y[:divider]\n",
    "y_test = y[divider:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std_dev = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std_dev\n",
    "X_test = (X_test - mean) / std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is necesseary because the independent variable has a different range in term of its value, so we will be using StandardScaler to have all the independent feature in the same range of scale. <br>\n",
    "We use StandardScaler because its ensure all the features contribute equally to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = None\n",
    "        self.coeff_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis = 1)\n",
    "        betas = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "        self.intercept_ = betas[0]\n",
    "        self.coeff_ = betas[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.coeff_) + self.intercept_\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root mean Squarred Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation with R2Score:  0.7023616105300725\n",
      "Model Evaluation with MAE:  51991.62760647411\n",
      "Model Evaluation with RMSE:  63045.642663314866\n"
     ]
    }
   ],
   "source": [
    "print('Model Evaluation with R2Score: ', r2_score(y_test, y_pred))\n",
    "print('Model Evaluation with MAE: ', mean_absolute_error(y_test, y_pred)) \n",
    "print('Model Evaluation with RMSE: ', root_mean_squared_error(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[329086.44143211 259900.        ]\n",
      " [244896.87318392 229900.        ]\n",
      " [343616.58762908 255000.        ]\n",
      " [471601.03560062 599000.        ]\n",
      " [278892.40313057 242500.        ]\n",
      " [355749.60217459 287000.        ]\n",
      " [240097.50425028 239500.        ]\n",
      " [280691.52827685 232000.        ]\n",
      " [360215.04339511 399900.        ]\n",
      " [205501.41498308 179900.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.printoptions(precision=2)\n",
    "y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "result = np.concatenate((y_pred_reshaped, y_test_reshaped), axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment No 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning model\n",
    "<img src = 'overfitting_2.png'>\n",
    "<img src ='model-complexity-vs-model-overfitting-vs-model-accuracy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to avoid Underfitting?<br>\n",
    "Underfitting happens when a model <b> has not learned the patterns in the training data well and is unable to generalize well on the new data</b><br>\n",
    "1. Underfit model has <b>poor training data performance </b> making it unreliable for prediction.<br>\n",
    "2. Happens because <b>high bias and low variance</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>There are several ways to avoid underfiting such as:</b><br>\n",
    "1. Increase Model Complexity<br>\n",
    "Using a more complex model that can capture more patterns in the data.<br>\n",
    "For startes, if we are using Linear Regression to predict something, consider using a Polynomal Regression or more sophisticated algorithms like decisions tree, random forest, etc that can capture more pattern in the given data.\n",
    "<br>\n",
    "\n",
    "2. Regularization<br>\n",
    "Regularization techniques like L1 and L2 regularization are used to prevent overfitting by penalizing large coefficients. <br>\n",
    "\n",
    "3. Increase Training Data<br>\n",
    "Insufficient training data can also lead to underfitting, especially if done by complex model. it would be good to collect more data with more variations to provide the model a good learning source. <br>\n",
    "\n",
    "4. Cross - Validation<br>\n",
    "Techniques like cross - validation will evaluate model's performance on multiple subsets of data, if there too many poor performance on different datasets, then the model is underfit, and needs to be fixed.<br>\n",
    "\n",
    "5. Feature engineering<br>\n",
    "Add more relevant feature to the model / data and remove unrelevant feature. By doing Feature Engineering, we can provide more information to the model.<br>\n",
    "\n",
    "6. Reduce Noise <br>\n",
    "Noisy features or outliers can hinder model's ability to learn meaningful patterns. We need to preprocess data to remove outliers, smooth noisy features.\n",
    "\n",
    "source:\n",
    "1. https://www.simplilearn.com/tutorials/machine-learning-tutorial/overfitting-and-underfitting<br>\n",
    "2. https://www.javatpoint.com/overfitting-and-underfitting-in-machine-learning<br>\n",
    "3. https://www.ibm.com/topics/underfitting#:~:text=Underfitting%20occurs%20when%20a%20model,poor%20performance%20of%20the%20model.<br>\n",
    "4. https://algorit.ma/blog/data-science/overfitting-underfitting/<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain two types of Regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizations are technique to calibrate machine learning models to <b>minimize adjusted loss function, and penalizing large coefficients</b> in order to avoid <b>underfitting or overfitting.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalty "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = '1_zMLv7EHYtjfr94JOBzjqTA.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of regularization:\n",
    "1. L1 Regularization also known as <b>Lasso Regression</b><br>\n",
    "    a. L1 Regularization adds the penalty to the cost function, the absolute values of the model coefficients.<br>\n",
    "    b. The penalty term is calculated as the sum of the absolute values of the coefficients multiplied by regularization parameter (lambda or alpha).<br>\n",
    "    c. L1 Regularization encourages sparsity in the model, meaning it tends to force the coefficients of less importants feature to zero, effectively performing feature selection.<br>\n",
    "    d. L1 Regularization is useful when dealing with high - dimensional datasets with many irrelevant features.\n",
    "\n",
    "2. L2 Regression, also known as <b>Ridge Regression</b><br>\n",
    "    a. L2 Regularization adds a penalty term to the cost function proportional to the squared values of model coefficients.<br>\n",
    "    b. The penalty term is calculated of the squared values of the coefficients multiplied by regularization parameter (lambda or alpha).<br>\n",
    "    c. L2 Regularization penalize the large coefficients, making it more smooth rather penalize the small coefficients.<br>\n",
    "    d. L2 does not enforce sparcity in the model, rather it shrinks the coefficients of all features toward zero, but rarely to exaclty zero.<br>\n",
    "    e. L2 Regularization is effective at reducing the impact of multicollinearity (correlation between features) by spreadubg the coefficients weight accross correlated features.\n",
    "\n",
    "\n",
    "Source<br>\n",
    "https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning#:~:text=Regularization%20refers%20to%20techniques%20that,on%20an%20over%2Dfitted%20model<br>\n",
    "https://www.javatpoint.com/regularization-in-machine-learning<br>\n",
    "https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate output k-fold Cross-Validation\n",
    "<img src = '1_PdwlCactbJf8F8C7sP-3gw.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do k fold, there are several steps needs to do before doing k fold validation such as:\n",
    "1. Randoming / shuffling sample data<br>\n",
    "    We need to shuffle the datasets that is randomly distributed across folds to prvent bias in the cross - validation process.\n",
    "\n",
    "2. Splitting Data into Training and Test Sets<br>\n",
    "    Before performing k - fold cross - validation, we need to separate test set to evaluate the model's final performacne after hyperparameter tuning.\n",
    "\n",
    "3. Define K<br>\n",
    "    To perform how many K - fold cross validation \n",
    "\n",
    "Cross validation procedure:\n",
    "1. Divide the training data into k folds, where each folds \n",
    "    acts as a validation set once, and the rest is used for training\n",
    "\n",
    "2. Traing the model K times, where each fold helds different\n",
    "    training and validation datasets.\n",
    "\n",
    "3. Evaluate model's performance using evaluation metrics such as RMSE. <br>\n",
    "\n",
    "4. Compute the average performance metric accross the folds\n",
    "\n",
    "\n",
    "source:\n",
    "1. https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training set: [ 7  3  2  8  1 10  6]\n",
      "Validation set: [4]\n",
      "\n",
      "Fold 2:\n",
      "Training set: [ 4  3  2  8  1 10  6]\n",
      "Validation set: [7]\n",
      "\n",
      "Fold 3:\n",
      "Training set: [ 4  7  2  8  1 10  6]\n",
      "Validation set: [3]\n",
      "\n",
      "Fold 4:\n",
      "Training set: [ 4  7  3  8  1 10  6]\n",
      "Validation set: [2]\n",
      "\n",
      "Fold 5:\n",
      "Training set: [ 4  7  3  2  1 10  6]\n",
      "Validation set: [8]\n",
      "\n",
      "Test set : [9 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.array([[10], [9], [8], [7], [6], [5], [4], [3], [2], [1]])\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "\n",
    "train_test_split_index = int(0.8 * len(dataset))  \n",
    "train_set = dataset[:train_test_split_index]\n",
    "test_set = dataset[train_test_split_index:]\n",
    "\n",
    "k = 5\n",
    "samples_per_fold = len(train_set) // k\n",
    "\n",
    "for i in range(k):\n",
    "    start_index_val = i * samples_per_fold\n",
    "    end_index_val = (i + 1) * samples_per_fold\n",
    "\n",
    "    validation_set = train_set[start_index_val:end_index_val]\n",
    "\n",
    "    \n",
    "    training_set = np.concatenate((train_set[:start_index_val], train_set[end_index_val:]))\n",
    "\n",
    "    print(f'Fold {i+1}:')\n",
    "    print(\"Training set:\", training_set.flatten())\n",
    "    print(\"Validation set:\", validation_set.flatten())\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Test set :\", test_set.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average output of 5-fold cross-validation: 5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset = np.array([[10], [9], [8], [7], [6], [5], [4], [3], [2], [1]])\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "validation_outputs = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(dataset):\n",
    "    \n",
    "    X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "    validation_output = X_test.mean()  \n",
    "    validation_outputs.append(validation_output)\n",
    "\n",
    "\n",
    "average_output = np.mean(validation_outputs)\n",
    "print(\"Average output of 5-fold cross-validation:\", average_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using datasets from number 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation score of 5-fold cross-validation: 0.5271896772950105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "data = pd.read_csv('home.txt', names = ['size', 'bedroom', 'price'])\n",
    "X = data[['size', 'bedroom']]\n",
    "y = data['price']\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "validation_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    score = r2_score(y_pred, y_test)\n",
    "    validation_scores.append(score)\n",
    "\n",
    "\n",
    "average_score = np.mean(validation_scores)\n",
    "print(\"Average validation score of 5-fold cross-validation:\", average_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
